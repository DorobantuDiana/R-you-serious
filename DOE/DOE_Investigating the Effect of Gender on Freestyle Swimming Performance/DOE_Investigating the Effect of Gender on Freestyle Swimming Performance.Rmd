---
title: "Investigating the Effect of Gender on Freestyle Swimming Performance: Implications for Transgender Athletes in Female Sports"
author: "Diana Dorobantu"
date: "April 25, 2023"
output: pdf_document
subtitle: TMA4267 Linear Statistical Models Spring 2023
abstract: "The issue of transgender athletes competing in female sports has sparked intense debate in recent years, with concerns raised about the potential advantages that transgender female athletes may have over their cisgender counterparts. Using Design of Experiments (DOE) methodology, the aim of this project is to explore the impact of gender on freestyle swimming performance, which is a critical area of concern in this debate. The study will involve analyzing the time laps of male and female swimmers to gain insights into the differences in technique and speed between the two genders.The experiment will utilize a k-factor design with two levels per factor to systematically evaluate the effects of each factor and their interactions on the time taken to complete the task. The experimental design will be generated using R/R-Studio, and a randomized experimental plan will be followed. The time taken to complete the task will be recorded and analyzed using statistical techniques such as Analysis of Variance (ANOVA) and regression analysis.The results of this study will provide valuable information on the extent to which gender affects performance in freestyle swimming and its potential implications for transgender athletes in female sports."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
# Load packages
pacman :: p_load(pacman, stats, AlgDesign, lattice)

# Warnings will be suppressed and will not be displayed in the console or any output                 
options(warn=-1) 
```

# Issue addressed 
In recent years, the issue of transgender athletes in female sports has been a topic of intense debate. One particular area of concern is freestyle swimming, where gender may play a significant role in performance. As a swimmer myself, I have witnessed firsthand the differences in technique and speed between male and female swimmers. In this project, I aim to explore the effect of gender on freestyle swimming and its implications for transgender athletes in female sports. By examining the time laps of male and female swimmers, I hope to gain a deeper understanding of the impact gender has on performance in this sport.

# Selection of Factors and Levels 

Based on the problem described, the relevant factors could be: Gender (Male [1] vs. Female[0]), Warm-up time (short [0] vs. long[1]), Breathing technique (bilateral[2] vs. unilateral[1]) and Distance (50m vs. 100m).

It is possible that there may be interactions between some of the factors, such as the effect of breathing technique being more pronounced for longer distances or for one gender versus the other.

The levels for each factor could be determined based on common practice or existing research. For example, warm-up times could be set to 5 minutes and 10 minutes, as those are commonly used warm-up durations. Bilateral breathing and unilateral breathing could be the two levels for the breathing technique factor, as those are the two most common techniques used by swimmers. For distance, 50m and 100m could be used as those are common race distances.

To control that the factors are at the desired level, the experiment could be conducted in a controlled environment such as a swimming pool with standardized conditions. The swimmers could be given specific instructions on the warm-up time and breathing technique to use. The distance swam could be measured precisely using timing equipment and markers on the pool deck.


# Selection of Response Variable

The response variable of interest is the Time it takes for the swimmer to complete the designated distance. There may be other response variables of interest such as: Heart Rate, Oxygen Consumption, Stroke Count or Stroke Rate, but for the purposes of this study I consider that Time is the most relevant response variable.

The response variable can be measured using accurate timing equipment such as a stopwatch or touch pads. The experiment could also be recorded using video equipment to allow for further analysis and measurement. For this trial a stopwach was used.

The accuracy of the measurements can be ensured by using standardized timing devices, as well as conducting multiple trials to obtain an average time for each factor combination. The accuracy of the measurements can also be improved by having multiple trained individuals measure the time to reduce measurement errors.

# Implementation of the experiment

To ensure the validity of the experiment, it is crucial to adhere to a randomization process when assigning treatments to experimental units. Any deviation from proper randomization can introduce bias and decrease the accuracy of the results. It is also important to ensure that each trial is a genuine replicate, performed independently and constituting a full trial, to account for the total variability of the experiment and increase the reliability of the results. Without genuine replicates, the variability in the results may not be fully accounted for, leading to less accurate conclusions. In my particular experiment, I conducted the trials over multiple mornings and then calculated the average of the runs to increase the accuracy of the results.

```{r echo=FALSE, fig.height=8, fig.width=8}
data <- read.csv("./data.csv", sep=",")
data
```

# Choice of design:

A 2k factorial design may be appropriate based on the number of factors and levels involved. The required resolution of the design will depend on the expected level of interaction between the factors. If there is a possibility of a high degree of interaction, a higher resolution design may be needed. A blocked design may be desirable to control for extraneous variables that could influence the results. In my experiment, I conducted all trials in the morning following a week of preparation, including exercise, sleep, and diet, to ensure a fair trial. Replicates might also be necessary to ensure the reliability of the results and to estimate experimental error. In my case, I conducted multiple runs and calculated the average for the final result. Depending on the specific research question and available resources, a 2k-p fractional factorial design or other designs may also be considered.

```{r, include=FALSE}
# 2^k Design; k=4
design <- gen.factorial(levels=2, nVars=4, varNames = c("A", "B", "C", "D"))
design
```

# Analysis of data

```{r echo=FALSE, fig.height=6, fig.width=6}
# remove the "Run" column
data <- data[-1]
plot(data)
```

```{r echo=FALSE, fig.height=12, fig.width=12}
par(mfrow=c(3,2))
interaction.plot(data$Gender,data$Distance,data$Time)
interaction.plot(data$Gender,data$Warm,data$Time)
interaction.plot(data$Gender,data$Breath,data$Time)
interaction.plot(data$Distance,data$Warm,data$Time)
interaction.plot(data$Distance,data$Breath,data$Time)
interaction.plot(data$Warm,data$Breath,data$Time)
par(mfrow=c(1,1))
```

```{r, include=FALSE}
xyplot(Time ~ Gender | Distance, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)

xyplot(Time ~ Gender | Warm, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)

xyplot(Time ~ Gender | Breath, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)

xyplot(Time ~ Distance | Warm, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)

xyplot(Time ~ Distance | Breath, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)

xyplot(Time ~ Warm | Breath, data = data,
       panel = function(x, y, ...)
       {
         panel.xyplot(x, y, ...)
         panel.lmline(x, y, ...)
       }
)
```

```{r, include=FALSE}
par(mfrow=c(2,2))

boxplot(Time~Gender, data=data, main="Time by Gender",
        xlab="Gender",ylab="Time")

boxplot(Time~Distance, data=data, main="Time by Distance",
        xlab="Distance",ylab="Time")

boxplot(Time~Warm, data=data, main="Time by Warm",
        xlab="Warm",ylab="Time")

boxplot(Time~Breath, data=data, main="Time by Breath",
        xlab="Breath",ylab="Time")
par(mfrow=c(1,1))

boxplot(Time ~ Gender*Distance, data=data, ylab="Time", xlab="Gender.Distance")
boxplot(Time ~ Warm*Breath, data=data, ylab="Time", xlab="Warm.Breath")
```


# Modelling data

# Model 1
--> linear model that includes all four predictor variables (Distance, Warm, Breath, and Gender)

```{r echo=FALSE}
# Model the main effects
model1 = lm(Time ~ ., data = data)
summary(model1)
```

· Multiple R-squared value (0.9638) means that approximately 96.38% of the variation in "Time" can be explained by the predictor variables.

· F-statistic represents the overall significance of the model, and its associated p-value is 7.481e-08 which very small,            indicating that the model as a whole is a good fit for the data.

· Intercept coefficient (7.82000) represents the estimated average value of "Time" when all other predictor variables are zero.

· coefficients for "Distance"(0.50060), "Warm" (-2.97250), "Breath"(-0.68000) and "Gender"(-5.70000) indicate the estimated change in "Time" associated with a one-unit increase in each predictor variable, holding all other predictor variables constant; p-values associated with each coefficient suggest that "Distance", "Gender" and "Warm"are significant predictors of "Time," whereas "Breath" is not.

```{r, include=FALSE}
par(mfrow=c(1,3))

       # Check Heteroscedasticity #

# Obtain residuals for model 1
res <- residuals(model1)

# Create residual vs. fitted plot for Model1
plot(res ~ fitted(model1), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 1")

# Add a horizontal line at 0 
abline(0,0)

      
    # Check Normality of Residuals Distribution #

# Create Q-Q plot for residuals in Model1
qqnorm(res)

# Add a straight diagonal line to the plot
qqline(res) 

plot(density(res))
```

# Model 2
--> quadratic model that includes the four predictor variables and all their two-way interactions (Distance:Warm, Distance:Breath, Distance:Gender, Warm:Breath, Warm:Gender, and Breath:Gender)

```{r echo=FALSE}
# Model the main effects plus two-factor interactions
model2 = lm(Time ~ .^2, data = data)
summary(model2)
```

· Multiple R-squared value (0.9995) means that approximately 99.95% of the variation in "Time" can be explained by the predictor variables.

· F-statistic represents the overall significance of the model, and its associated p-value is 1075 which very large,      indicating that there is a large difference between the means of the groups being compared, therefore the model is not significant.

```{r, include=FALSE}
par(mfrow=c(1,3))

       # Check Heteroscedasticity #

# Obtain residuals for model 2
res2 <- residuals(model2)

# Create residual vs. fitted plot for Model2
plot(res2 ~ fitted(model2), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 2")

# Add a horizontal line at 0 
abline(0,0)

      
    # Check Normality of Residuals Distribution #

# Create Q-Q plot for residuals in Model2
qqnorm(res2)

# Add a straight diagonal line to the plot
qqline(res2) 

plot(density(res2))
```

# Model 3
--> cubic model that includes the four predictor variables, all their two-way interactions, and all their three-way interactions (Distance:Warm:Breath, Distance:Warm:Gender, Distance:Breath:Gender, and Warm:Breath:Gender)

```{r echo=FALSE}
# Model the main effects plus three-factor interactions
model3 = lm(Time ~ .^3, data = data)
summary(model3)
```

· Multiple R-squared value (0.9999) means that approximately 99.99% of the variation in "Time" can be explained by the predictor variables.

· F-statistic represents the overall significance of the model, and its associated p-value is 612 which very large, indicating this model is not significant as well.

```{r, include=FALSE}
par(mfrow=c(1,3))

       # Check Heteroscedasticity #

# Obtain residuals for model 3
res3 <- residuals(model3)

# Create residual vs. fitted plot for Model3
plot(res3 ~ fitted(model3), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 3")

# Add a horizontal line at 0 
abline(0,0)

      
    # Check Normality of Residuals Distribution #

# Create Q-Q plot for residuals in Model3
qqnorm(res3)

# Add a straight diagonal line to the plot
qqline(res3) 

plot(density(res3))
```


```{r, include=FALSE}
# Compare the three models
anova(model1, model2, model3)

# This output shows the results of an analysis of variance (ANOVA) for three different models of the relationship between the variables Time, Distance, Warm, Breath, and Gender.
 
# The F-statistic tests whether adding the additional predictor variables and interactions in the more complex models (Model 2 and Model 3) significantly improve the fit of the model compared to the simpler model (Model 1).

# In this case, the p-value for the F-test for Model 2 (comparing Model 1 to Model 2) is 0.1067, which suggests that the improvement in fit between Model 1 and Model 2 is not statistically significant at the 0.05 level.

# The p-value for the F-test for Model 3 (comparing Model 2 to Model 3) is 0.6888, which suggests that the improvement in fit between Model 2 and Model 3 is also not statistically significant at the 0.05 level.

# Therefore, there is no evidence to suggest that the more complex models (Model 2 and Model 3) provide a significantly better fit to the data than the simpler linear model (Model 1).
```

# Model 4
-->  full model that includes the four predictor variables and all their interactions up to four-way interaction (Distance:Gender:Warm:Breath)

```{r echo=FALSE}
# Full model including four-factor interactions
model4 = lm(Time ~ .^4, data = data)
summary(model4)
```

· Since we have no replicates, we have no way of assessing the significance of any of the coefficients of this full model with all interactions.

· All of the estimated coefficients and standard errors are missing and replaced with "NaN". This is due to a perfect fit of the model to the data, resulting in all residuals being zero. Therefore, the model explains all of the variation in the data and the estimated coefficients are not meaningful. The adjusted R-squared value is also not reported because it requires non-zero residual degrees of freedom. The F-statistic is not meaningful because the denominator degrees of freedom are zero. Overall, this output suggests that the model is not useful for making inferences or predictions on new data.

```{r, include=FALSE}
par(mfrow=c(1,3))

       # Check Heteroscedasticity #

# Obtain residuals for model 4
res4 <- residuals(model4)

# Create residual vs. fitted plot for Model4
plot(res4 ~ fitted(model4), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 4")

# Add a horizontal line at 0 
abline(0,0)

      
    # Check Normality of Residuals Distribution #

# Create Q-Q plot for residuals in Model4
qqnorm(res4)

# Add a straight diagonal line to the plot
qqline(res4) 

plot(density(res4))
```


# Conclusion and Recommendations

From the statistical analysis of Model 1 we saw that "Breath" it is not a significant predictor, therefore we create another model exluding it.

# Model 5
--> linear model that includes three predictor variables (Distance, Warm, Gender)

```{r echo=FALSE}
model5 = lm(Time ~ Distance + Warm  + Gender, data = data)
summary(model5)
```
(1) In the Residual Plots we can see that the spread of the residuals tends to be higher for lowest and highest fitted values in both models, but it doesn’t look serious enough that we would need to make any changes to the models.

(2) In the Q-Q Plots we can see that the residuals tend to stray from the line quite a bit near the tails in both models, which could indicate that they’re not normally distributed.

(3) In the Density Plot for Model 1 we can see that the density roughly follows a bell shape which enforce that the residuals are not normally distributed. In comparison, Model 5 is more suitable as follows more a bell shape, but moving forward we can decide to perform a transformation on the data to ensure that the residuals are more normally distributed.

```{r echo=FALSE}
par(mfrow=c(2,3))

       # Check Heteroscedasticity #

# Obtain residuals for model 5
res5 <- residuals(model5)

# Create residual vs. fitted plot for Model4
plot(res5 ~ fitted(model5), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 5")

# Add a horizontal line at 0 
abline(0,0)

    # Check Normality of Residuals Distribution #

# Create Q-Q plot for residuals in Model5
qqnorm(res5)

# Add a straight diagonal line to the plot
qqline(res5) 

plot(density(res5))



# vs Model1

plot(res ~ fitted(model1), xlab = "Fitted values", ylab = "Residuals",
     main = "Residual Plot for Model 1")
abline(0,0)
qqnorm(res)
qqline(res) 
plot(density(res))
```
  
# ANOVA
```{r echo=FALSE, fig.height=8, fig.width=8}
# Compare the models
anova(model1, model5)
```
· In this case, Model 1 has 11 Residual Degrees of Freedom and a Residual Sum of Squares of 29.831, while Model 5 has 12 Residual Degrees of Freedom and a Residual Sum of Squares of 31.680. The change in degrees of freedom between the two models is -1, indicating that Model 1 has one more parameter than Model 2. The change in Residual Sum of Squares between the two models is -1.8496, indicating that Model 1 fits the data better than Model 5. However, the F-statistic of 0.682 is not significant at the 0.05 level( p-value of 0.4264 > 0.05). Therefore, the ANOVA table shows that the difference between the two models is not statistically significant, as the F-statistic is not large enough to reject the null hypothesis that the two models are equivalent. This suggests that the "Breath" variable does not provide significant additional explanatory power for the response variable Time beyond that provided by the other three predictor variables included in Model 5.

To summarize our experiment, Model 1 emerged as the optimal choice, and we can assert that gender plays a highly influential role in performance within this particular sport. Furthermore, the other explanatory models also support this notion, emphasizing the crucial implications of gender on performance in freestyle swimming.